Please go to the following link to see the detail presentation: https://aithoughtlab.github.io/ThinkingAI/projects/ 

Collaborator: [zemin-xu](https://github.com/zemin-xu/BrainTumorEstimation)

Supervisor: [M. PREDA](https://scholar.google.com/citations?user=Dx9C-0sAAAAJ)

A pipeline composed of tumor detection in human brain using deep learning and visualization using Mixed Reality(MR) technology.

---

## Problematic

The recent advancement in processing power of computers have enabled tremendous opportunities for the increased use of virtual reality (VR) and augmented reality (AR) technology in medicine and surgery. The visualization of human organs in the 3D environment takes a central role in the procedure of diagnosis and the follow up treatment of any disease. An automated immersive visualization of a human brain from a sequence of 2D MRI images in the MR environment is necessary not only to detect and classify the nature of tumors but also it helps surgeons to approach the tumor from a virtual perspective and to plan a possible surgery ahead of time. In this work, we adapt an approach for a possible immersive visualization of the human brain in the VR environment and consequently propose the best two possible tumor locations using U-Net deep learning framework.

## Research aim

The aim of this research work is to develop a tool for an immersive visualization of human brain tumors in the MR environment in order to facilitate the surgical procedures.

1. Analyze MRI data using a 3D-point-cloud-generation.

2. Integrate a state of the art Deep Learning framework, known as U-Net with the MR application in order to detect the potential brain tumor location.

3. Building an MR tool for brain surgeons in order to have an immersive visualization before participating in a real surgical environment.

